\chapter{Referencial teórico}

Este capítulo descreve os principais elementos teóricos utilizados no
desenvolvimento desta pesquisa. As seções \ref{sec:red_neu} e \ref{sec:red_tip}
resumem os principais conceitos sobre redes neurais, assim como as principais
técnicas utilizadas nesta área. A seção \ref{sec:red_khn} é dedicada
especificamente as redes de Kohonen, descrevendo sua estrutura conceitual e seu
algorítimo de treinamento, esta categoria de rede neural é o núcleo da técnica
de \textit{clustering} de imagens proposta neste trabalho, assunto abordado no
próximo capítulo. Uma breve formalização dos descritores de Hu é feita na seção
\ref{sec:desc_hu}. E por fim, alguns conceitos chave sobre imagens digitais são
apresentados na seção \ref{sec:img_dig}.

\section{Fala}
A fala é a forma de comunicação mais utilizada pelos seres humanos.\cite{RvPatrick} Através da fala, o cérebro humano consegue interpretar informações extremamente complexas, tais como identificar a pessoa que está falando, sua posição no espaço físico, seu estado emocional e outros dados como a ironia, seriedade ou tristeza. Os computadores, apesar de fazerem cálculos mais rápidos que o homem, não conseguem reconhecer através da fala informações como os seres humanos.

\subsection{Vantagens da comunicação pela fala em sistemas homém-máquina}

Segundo \cite{RavDigitalSadaoki} podemos citar:

\begin{itemize}
\item Natural: Não precisa de treinamento especial e nem de habilidades especiais;
\item Rapidez: A informação é transmitida mais rapidamente que pelas outras formas de comunicação.
\item Flexível: Deixa as mãos, olhos livres;
\item Eficiente: Tem uma elevada taxa de informação;
\end{itemize}

\subsection{Desvantagens no uso da fala em sistemas homem-máquina}
Mesmo possuindo vantagens significativas, a comunicação por fala também possui desvantagens, como \cite{RavDigitalSadaoki} descreveu:

\begin{itemize}
\item Ruidos: O sistema fica suscetível a interferência do ambiente, necessitando de um removedor de ruídos para ambientes com alto índice de ruídos.
\item Diversidade da língua: Características que variam de pessoa para pessoa, como sotaque, velocidade da fala, condições físicas e emocionais do locutor. 
\end{itemize}
%Tentar procurar mais desvantanges e argumentos para diversidade.

\section{O Sistema de Reconhecimento de Voz}\label{sec:red_khn}
Sistemas de reconhecimento automático de voz, tem como objetivo, transformar um sinal analógico(fala) obtido através de um transdutor, mapeando-o a fim de produzir como saída a palavra, uma sequencia de fonemas ou uma sentenças correspondentes ao sinal de entrada. Com o resultado da tradução, pode-se tomar decisões, traduzir para outra língua, etc.
Reconhecedores de voz, podem ser divididos em três grandes classes: reconhecimento por comparação de padrões, reconhecimento baseado na análise acústico-fonética
O sistema de reconhecimento de voz pode ser dividido em quarto fases: aquisição do sinal de voz, pré-processamento,
extração de informações e geração dos padrões de voz. \cite{RavIsoladas}

\subsection{Histórico dos Sistemas de Reconhecimento de Voz}\label{sec:red_khn}

Sistemas de reconhecimento automático de voz vem sendo estudados desde os anos 50 nos laboratórios Bell, quando foi criado, o primeiro reconhecedor de dígitos isolados com suporte a um locutor.\cite{Historico1} As redes neurais também surgiram nos anos 50, mas não houve prosseguimento nos estudos, devido a problemas práticos. Muitos reconhecedores de voz, foram criados nas décadas de 50 e 60.\cite{RavSpeechSadaoki} No início dos anos 70, surgiram os algoritmos para sistemas de fala contínua, graças as técnicas de \textit{Linear Predictive Coding} (LPC) e \textit{Dynamic Time Warping} (DTW). \cite{FundamentRabiner} E os anos 80 foram marcados pela disseminação dos metodos estáticos, como \textit Modelos Ocultos de Markov (HMM). \cite{FundamentRabiner} Esse período foi de grande evolução para os sistemas de reconhecimento de voz, as redes neurais passaram a ser usadas no desenvolvimento dos sistemas, sendo possível implementar sistemas mais robustos, com vocabulários grandes e com taxas de acerto de mais de 90{\%}.\cite{AvaliaTecJose} 

\subsection{Características de Sistemas RAV}\label{sec:red_neu}

Existem várias maneiras de categorizar um sistema de reconhecimento de voz, os mais importantes são: o estilo de pronuncia que é aceito, ao tamanho do vocabulário e à dependência ou independencia do locutor. \cite{Carac1} Essas categorias que definem a precisão do sistema de reconhecimento.

\subsubsection{Dependência do locutor}
Podemos classificar sistemas de reconhecimento como dependentes e independentes do locutor. Um sistema dependente de locutor reconhece a fala das pessoas cujas vozes foram utilizadas para treinar o sistema, apresentando uma pequena taxa de erros, para o locutor para qual foi treinado o sistema,  implementação mais simples que sistemas independentes do locutor, que reconhecem a fala de qualquer pessoa com uma taxa de acerto aceitável. Neste caso é necessário realizar o treino do sistema com uma base que inclua diferentes pessoas com diferentes idades, sexo, sotaques, etc. O que dificulta a construção desses sistemas.

\subsubsection{Modo de pronúncia}
Sistemas RAV podem ser classificados quanto ao modo de pronúncia de duas formas, sistemas de palavras isoladas e os de fala conectadas(contínua). Reconhecedor de palavras isoladas são sistemas que reconhecem palavras faladas isoladamente, isto é, entre cada palavra deve existir uma pausa mínima, para que seja detectado o início e o fim da mesma. Isso proporciona um resultado muito superior aos de fala contínua, estes sistemas são os mais simples de serem implementados. Um exemplo clássico de reconhecedores de palavras isoladas são os reconhecedores de dígitos, que alcançam taxa de menos de 2{\%} de erro para dígitos de 0 à 10.\cite{RavPtBr}
Já o reconhecedor de palavras conectadas são sistemas mais complexos que os de palavras isoladas e utilizam palavras como unidade fonética padrão. São capazes de reconhecer sentenças completas, pronunciadas sem pausa entre as palavras, e por isso não se tem informação de onde começam 
e terminam determinadas palavras, muitas palavras são mascaradas, encurtadas e as vezes não 
pronunciadas. Esses sistemas precisam lidar com todas as características e vícios da linguagem natural, como o sotaque, a duração das palavras, a pronúncia descuidada, etc. Tornando ainda mais difíceis as tarefas do reconhecedor em casos como “ele vai morrer em dois dias” que 
muitas vezes  é dito como “ele vai morrerem dois dias”.\cite{RavPtBr}

\subsubsection{Tamanho do vocabulário}
Um fator muito importante na precisão de um RAV, é o tamanho do vocabulário, quanto maior seu tamanho, maior a quantidade de palavras ambíguas, com realizações sonoras semelhantes, ocasionando maior chance de erros por parte do decodificador responsável pelo reconhecimento.\cite{RavPtBr} Segundo \cite{RavIsoladas} vocabulários podem ser definidos como:

\begin{itemize}
\item Vocabulário pequeno: reconhecem até 20 palavras. 
\item Vocabulário médio: reconhecem entre 20 e 100 palavras. 
\item Vocabulário grande: reconhecem entre 100 e 1000 palavras. 
\item Vocabulário muito grande: reconhecem mais de 1000 palavras. 
\end{itemize}

Sistemas RAV com suporte a grandes vocabulários são chamados de Large Vocabulary Continuos Speech Recognition (LVCSR). Existem muitas dificuldades encontradas na criação de sistemas LVCSR, como: a disponibilidade de um corpus de voz digitalizada e transcrita grande o suficiente para treinamento do sistema, recursos como bases de textos de
tamanho elevado e um dicionario fonético de amplo vocabulário.\cite{RvPatrick}
\subsubsection{Perplexidade} 

\subsubsection{Relação sinal – ruído}

\begin{figure}[H]
\centering
\input{./graficos/neuronio}
\caption{Texto da figura}
\end{figure}

\subsection{Fatores que Interferem no Desempenho}

\chapter{Modelos Ocultos de Markov}

\chapter{Resultado}

\subsubsection{Processo competitivo}

Quando uma entrada $ x = \left[x_1, x_2, ..., x_n\right]^T $ é apresentado à
rede, o neurônio da grade que melhor responder a este padrão será ativado, este
neurônio é dito vencedor, e será recompensado ajustando-se seus componentes
para mais próximo do vetor de entrada.

O critério escolhido para determinar o neurônio vencedor é a distância
euclidiana entre o vetor de entradas e o vetor de pesos das sinapses do
neurônio, como indicado na equação \ref{eq:dit_ecl}:

\begin{equation}\label{eq:dit_ecl}
d_i(t) = \sqrt{\sum_{j = 1}^N \left( x_j(t) - w_{ij}(t) \right)^2}
\end{equation}

Onde:

\begin{itemize}
\item $ d_i(t) $ é a distância euclidiana entre o vetor de pesos do
neurônio $ i $ e o vetor de entradas na iteração $ t $;
\item $ i $ é o índice do neurônio da grade;
\item $ j $ é o índice do neurônio de entrada;
\item $ N $ é o número de entradas;
\item $ x_j(t) $ é o sinal de entrada na entrada $ j $ na iteração $ t $;
\item $ w_{ij}(t) $ é o valor do peso sináptico entre o neurônio de
entrada $ j $ e o neurônio da grade $ i $ na iteração $ t $.
\end{itemize}

\subsubsection{Algoritmo geral de treinamento}

O algoritmo \ref{alg:trei_khn} resume as três etapas anteriores e descreve
todo o processo de treinamento de uma rede de Kohonen:
%\clearpage

\begin{algorithm}[H]
\caption{Treinamento de uma rede de Kohonen}\label{alg:trei_khn}
\SetAlgoRefName{alg:trei_khn}
\Entrada{$ \sigma_0 $ , $ \tau_l $ , $ \eta_0 $ e o valor do \textit{erro} }
\Inicio{
  \Repita{distâncias auclidianas $ \le $ erro}{
    Calcular a \textit{largura efetiva} $ \sigma(t) $\;
    Calcular a \textit{vizinhança topológica} $ h $\;
    Calcular a \textit{taxa de aprendizado} $ \eta(t) $\;
    \ParaCada{conexão}{
      Calcular $ \Delta w $\;
      Ajustar o arco\;
    }
  }
}
\end{algorithm}

\section{Descritores de Hu}\label{sec:desc_hu}

Os descritores de Hu são um conjunto de sete momentos invariantes a rotação,
translação e escala.

O momento bidimensional de ordem $ (p+q) $ é dado pela
equação \ref{eq:mm_bid_cont}:

\begin{equation}\label{eq:mm_bid_cont}
m_{pq} = \iint x^p y^q f(x, y) \mathrm{d}x \mathrm{d}y, p, q \in
\end{equation}

A equação num domínio discreto, pode ser reescrita na forma:

\begin{equation}\label{eq:mm_bid_disc}
m_{pq} = \sum_{x, y} x^p y^q f(x, y), p, q \in
\end{equation}

A massa total da função $ f(x, y) $ é determinado pelo
momento $ m_{00} $, conforme a equação \ref{eq:mm_bid_m00}:

\begin{equation}\label{eq:mm_bid_m00}
m_{pq} = \sum_{x, y} f(x, y), p, q \in
\end{equation}

Existe um ponto no qual a aplicação pontual da massa total gera o mesmo momento
que a massa distribuída, este ponto é dito centroide de $ f(x, y) $ e suas
coordenadas $ x $ e $ y $ são dadas pela equação \ref{eq:ct_xy}:

\begin{subequations}\label{eq:ct_xy}
\begin{align}
    \bar{x} = \frac{1}{ m_{00} } \sum x f(x, y) = \frac{ m_{10} }{ m_{00} } \\
    \bar{y} = \frac{1}{ m_{00} } \sum y f(x, y) = \frac{ m_{01} }{ m_{00} }
\end{align}
\end{subequations}

O momento central é obtido se deslocando a imagem para o centroide,
da seguinte forma:

\begin{equation}\label{eq:mm_ctr}
\mu_{pq} = \sum_{x, y} (x - \bar{x})^p (y - \bar{y})^q f(x, y)
\end{equation}

Ainda é necessário normalizar o momento para que os valores resultantes não sejam
extremos a ponto de serem ignorados pelo sistema de reconhecimento de padrões. O
momento central de ordem $ (p+q) $ normalizado é obtido dividindo o momento
central de $ y $ mesma ordem por um fator definido por $ \mu_{00}^\gamma $ ,
conforme indicado pela equação \ref{eq:mm_norm}:

\begin{subequations}\label{eq:mm_norm}
\begin{align}
    \gamma = 1 + \frac{ p + q }{2} \\
    \eta_{pq} = \frac{ \mu_{pq} }{ \mu_{00}^\gamma }
\end{align}
\end{subequations}

A partir dessas equações são estabelecidos sete momentos invariantes à translação,
 rotação e escala, chamados de momentos de Hu, ou descritores de Hu. São eles:

\begin{subequations}\label{eq:mmt}
\begin{align}
  \varphi_1 = \eta_{20} + \eta_{02} \\
  \varphi_2 = (\eta_{20} - \eta_{02})^2 + 4\eta_{11}^2 \\
  \varphi_3 = (\eta_{30} - 3\eta_{12})^2 + (3\eta_{21} - \eta_{03})^2 \\
  \varphi_4 = (\eta_{30} + \eta_{12})^2 + (3\eta_{21} + \eta_{03})^2 \\
%
  \varphi_5 = (\eta_{30} - 3\eta_{12})(\eta_{30} + \eta_{12})
               \left[ (\eta_{30} + \eta_{12})^2 - 3(\eta_{21} + \eta_{03})^2 \right] \\
              + (3\eta_{21} - \eta_{03})(\eta_{21} + \eta_{03})
               \left[ 3(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2 \right] \\
%
  \varphi_6 = (\eta_{20} - \eta_{02})
               \left[ (\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2 \right] \\
              + 4\eta_{11}(\eta_{30} - \eta_{12})(\eta_{21} + \eta_{03}) \\
%
  \varphi_7 = (3\eta_{21} - \eta_{30})(\eta_{30} + \eta_{12})
               \left[ (\eta_{30} + \eta_{12})^2 - 3(\eta_{21} + \eta_{03})^2 \right] \\
              + (3\eta_{12} - \eta_{03})(\eta_{21} + \eta_{03})
               \left[ 3(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2 \right]
\end{align}
\end{subequations}

\section{Imagens digitais}\label{sec:img_dig}

Imagens digitais são representações computacionais de imagens bidimensionais,
codificadas de modo a permitir seu armazenamento, exibição e manipulação por
dispositivos eletrônicos. Há dois tipos fundamentais de imagens digitais,
os mapas de bits (\textit{bitmaps}) e as imagens vetoriais.

\subsection{Mapas de bits}

Mapa de bists é a representação matricial de uma imagem, onde cada posição,
chamada de \textit{pixel}, armazena uma cor. Normalmente os \textit{pixels} são
codificados no padrão RGB (\textit{Red}, \textit{Green},\textit{Blue}), que
utiliza três \textit{bytes} para armazenar um inteiro para as cores vermelha,
verde e azul, respectivamente. Em mídias impressas é comum que as imagens
\textit{bitmaps} utilizem o padrão
CMYK (\textit{Cian}, \textit{Magenta}, \textit{Yelow}, \textit{Black}) ao invés
do RGB.

Embora uma imagem bitmap seja armazenada na RAM com todos os \textit{pixels}, é
comum, por uma questão de economia de memória e tempo de transmissão, a compressão
destes arquivos. Entre os principais formatos de compressão estão
o GIF (\textit{Graphics Interchange Format}), o JPEG
(\textit{Joint Photographic Experts Group}) e o PNG (\textit{Portable Network Graphics}).

\subsection{Imagens vetoriais}

As imagens vetoriais são formadas pela descrição geométrica de objetos.
Por serem compostas de vetores, este tipo de imagem ocupa menos espaço na
memória comparado com as bitmaps, e não perdem a qualidade quando
aplicado transformações de escala e rotação sobre elas.

